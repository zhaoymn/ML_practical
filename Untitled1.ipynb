{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "2\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "2\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "2\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "1\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "1\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "1\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "144\n",
      "150\n",
      "0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/Anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/Anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3146: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "/usr/local/Anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/usr/local/Anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "class NBC:\n",
    "    feature_num = 0\n",
    "    feature_type = 0\n",
    "    class_num = 0\n",
    "    train_data_num = 0\n",
    "    parameters = []\n",
    "    pB = []\n",
    "    pA = []\n",
    "    \n",
    "    def __init__(self,feature_types,num_classes):\n",
    "        self.feature_num = len(feature_types)\n",
    "        self.class_num = num_classes\n",
    "        self.feature_type = feature_types\n",
    "        self.parameters = [0 for i in range(self.feature_num)]\n",
    "        self.pB = [0 for i in range(self.feature_num)]\n",
    "        self.pA = [0 for i in range(self.class_num)]\n",
    "    \n",
    "    def get_gaussian_value(self, x, mean, sigma):\n",
    "        return 1.0*math.exp(-((x-mean)*(x-mean))/(2*sigma))/(math.sqrt(sigma*2*math.pi))\n",
    "    \n",
    "    def fit(self, Xtrain, ytrain):\n",
    "        self.train_data_num = len(ytrain)\n",
    "        for i in range(self.class_num):\n",
    "            self.pA[i] = dict()\n",
    "            self.pA[i][\"count\"] = 0\n",
    "            self.pA[i][\"p\"] = 0\n",
    "        for i in range(len(self.feature_type)):\n",
    "            self.pB[i] = dict()\n",
    "            self.parameters[i] = dict()\n",
    "            if self.feature_type[i] == 'b':\n",
    "                for j in range(len(ytrain)):\n",
    "                    \n",
    "                    item = Xtrain[j][i]\n",
    "                    if item in self.pB[i]:\n",
    "                        self.pB[i][item][\"count\"] = self.pB[i][item] + 1\n",
    "                    else:\n",
    "                        self.pB[i][item] = dict()\n",
    "                        self.pB[i][item][\"count\"] = 1\n",
    "                        self.pB[i][item][\"p\"] = 0\n",
    "                        \n",
    "                    if \"count\" in self.pA[ytrain[j]]:\n",
    "                        self.pA[ytrain[j]][\"count\"] = self.pA[ytrain[j]][\"count\"] + 1\n",
    "                    else:\n",
    "                        self.pA[ytrain[j]][\"count\"] = 1\n",
    "                        \n",
    "                    if item in self.parameters[i]:\n",
    "                        self.parameters[i][item][ytrain[j]] = self.pA[i][item][ytrain[j]] + 1\n",
    "                        self.parameters[i][item][\"total\"] = self.parameters[i][item][\"total\"] +1\n",
    "                    else:\n",
    "                        self.parameters[i][item] = dict()\n",
    "                        self.parameters[i][item][\"total\"] = 1\n",
    "                        for k in range(self.class_num):\n",
    "                            self.parameters[i][item][k] = 0\n",
    "                        self.parameters[i][item][ytrain[j]] = 1;\n",
    "                for key in self.pB[i].keys():\n",
    "                    self.pB[i][key][\"p\"] = self.pB[i][key][\"count\"]/self.train_data_num\n",
    "                for j in range(self.class_num):\n",
    "                    for item in self.parameters[i].keys():\n",
    "                        if j in self.parameters[i][item]:\n",
    "                            self.parameters[i][item][j] = self.parameters[i][item][j]/self.parameters[i][item][\"total\"]\n",
    "                        else:\n",
    "                            self.parameters[i][item][j] = 1e-6\n",
    "            else:\n",
    "                for j in range(self.class_num):\n",
    "                    temparray = []\n",
    "                    for k in range(len(ytrain)):\n",
    "                        if ytrain[k] == j:\n",
    "                            temparray.append(Xtrain[k,i])# = [temparray Xtrain[k,i]]\n",
    "                    self.parameters[i][j] = dict()\n",
    "                    self.parameters[i][j][\"mean\"] = np.mean(temparray)\n",
    "                    #print(self.parameters[i][j][\"mean\"]) \n",
    "                    #print(type(temparray))\n",
    "                    varian = np.var(temparray)\n",
    "                    if varian ==0:\n",
    "                        varian = 1e-6\n",
    "                    self.parameters[i][j][\"sigma\"] = varian\n",
    "                pass\n",
    "        for i in range(self.class_num):\n",
    "            self.pA[i][\"p\"] = self.pA[i][\"count\"]/self.train_data_num\n",
    "        \n",
    "    \n",
    "    def predict(self, Xtest):\n",
    "        probability = [0 for i in range(self.class_num)]\n",
    "        for i in range(self.class_num):\n",
    "            for j in range(len(self.feature_type)):\n",
    "                if self.feature_type[i] == 'b':\n",
    "                    if Xtest[j] in self.parameters[j]:\n",
    "                        probability[i] = probability[i] + np.log(self.parameters[j][Xtest[j]][i]*self.pA[i][\"p\"]/self.pB[j][Xtest[j]][\"p\"]+1e-6)\n",
    "                    else:\n",
    "                        probability[i] = probability[i] + np.log(1e-6)\n",
    "                else:\n",
    "                    probability[i] = probability[i] + np.log(self.get_gaussian_value(Xtest[j],self.parameters[j][i][\"mean\"],self.parameters[j][i][\"sigma\"]))\n",
    "        bestclass = 0;\n",
    "        value = probability[0]\n",
    "        for i in range(self.class_num):\n",
    "            if probability[i] > value:\n",
    "                value = probability[i]\n",
    "                bestclass = i\n",
    "        return bestclass\n",
    "\n",
    "Xtrain = [[1,0],[0,1]]\n",
    "ytrain = [0,1]\n",
    "Xtest = [1,0]\n",
    "nbc = NBC(['b','b'],2)\n",
    "nbc.fit(Xtrain, ytrain)\n",
    "print(nbc.predict(Xtest))\n",
    "iris = load_iris()\n",
    "X, y = iris['data'], iris['target']\n",
    "nbc = NBC(['r','r','r','r'],4)\n",
    "nbc.fit(X,y)\n",
    "correct = 0\n",
    "for i in range(len(y)):\n",
    "    print(\"  \")\n",
    "    print(nbc.predict(X[i,:]))\n",
    "    print(y[i])\n",
    "    if nbc.predict(X[i,:])==y[i]:\n",
    "        correct = correct + 1\n",
    "print(correct)\n",
    "print(len(y))\n",
    "print(correct/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
