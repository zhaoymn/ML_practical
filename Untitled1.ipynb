{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhao/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/zhao/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/zhao/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3146: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "/home/zhao/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/home/zhao/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/zhao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:98: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7065666666666676, 0.6735333333333342, 0.6681000000000011, 0.6673666666666678, 0.6671666666666679, 0.6670666666666678, 0.6670666666666678, 0.6670666666666678, 0.6670666666666678, 0.6670666666666678]\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "0\n",
      "0\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "2\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "2\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "2\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "1\n",
      "1\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "1\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "1\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "1\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "  \n",
      "2\n",
      "2\n",
      "144\n",
      "150\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pickle as cp\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "class NBC:\n",
    "    feature_num = 0\n",
    "    feature_type = 0\n",
    "    class_num = 0\n",
    "    train_data_num = 0\n",
    "    parameters = []\n",
    "    pB = []\n",
    "    pA = []\n",
    "    \n",
    "    def __init__(self,feature_types,num_classes):\n",
    "        self.feature_num = len(feature_types)\n",
    "        self.class_num = num_classes\n",
    "        self.feature_type = feature_types\n",
    "        self.parameters = [0 for i in range(self.feature_num)]\n",
    "        self.pB = [0 for i in range(self.feature_num)]\n",
    "        self.pA = [0 for i in range(self.class_num)]\n",
    "    \n",
    "    def get_gaussian_value(self, x, mean, sigma):\n",
    "        return 1.0*math.exp(-((x-mean)*(x-mean))/(2*sigma))/(math.sqrt(sigma*2*math.pi))\n",
    "    \n",
    "    def fit(self, Xtrain, ytrain):\n",
    "        self.train_data_num = len(ytrain)\n",
    "        for i in range(self.class_num):\n",
    "            self.pA[i] = dict()\n",
    "            self.pA[i][\"count\"] = 0\n",
    "            self.pA[i][\"p\"] = 0\n",
    "        for i in range(len(self.feature_type)):\n",
    "            self.pB[i] = dict()\n",
    "            self.parameters[i] = dict()\n",
    "            if self.feature_type[i] == 'b':\n",
    "                for j in range(len(ytrain)):\n",
    "                    \n",
    "                    item = Xtrain[j][i]\n",
    "                    if item in self.pB[i]:\n",
    "                        self.pB[i][item][\"count\"] = self.pB[i][item] + 1\n",
    "                    else:\n",
    "                        self.pB[i][item] = dict()\n",
    "                        self.pB[i][item][\"count\"] = 1\n",
    "                        self.pB[i][item][\"p\"] = 0\n",
    "                        \n",
    "                    if \"count\" in self.pA[ytrain[j]]:\n",
    "                        self.pA[ytrain[j]][\"count\"] = self.pA[ytrain[j]][\"count\"] + 1\n",
    "                    else:\n",
    "                        self.pA[ytrain[j]][\"count\"] = 1\n",
    "                        \n",
    "                    if item in self.parameters[i]:\n",
    "                        self.parameters[i][item][ytrain[j]] = self.pA[i][item][ytrain[j]] + 1\n",
    "                        self.parameters[i][item][\"total\"] = self.parameters[i][item][\"total\"] +1\n",
    "                    else:\n",
    "                        self.parameters[i][item] = dict()\n",
    "                        self.parameters[i][item][\"total\"] = 1\n",
    "                        for k in range(self.class_num):\n",
    "                            self.parameters[i][item][k] = 0\n",
    "                        self.parameters[i][item][ytrain[j]] = 1;\n",
    "                for key in self.pB[i].keys():\n",
    "                    self.pB[i][key][\"p\"] = self.pB[i][key][\"count\"]/self.train_data_num\n",
    "                for j in range(self.class_num):\n",
    "                    for item in self.parameters[i].keys():\n",
    "                        if j in self.parameters[i][item]:\n",
    "                            self.parameters[i][item][j] = self.parameters[i][item][j]/self.parameters[i][item][\"total\"]\n",
    "                        else:\n",
    "                            self.parameters[i][item][j] = 1e-6\n",
    "            else:\n",
    "                for j in range(self.class_num):\n",
    "                    temparray = []\n",
    "                    for k in range(len(ytrain)):\n",
    "                        if ytrain[k] == j:\n",
    "                            temparray.append(Xtrain[k,i])# = [temparray Xtrain[k,i]]\n",
    "                    self.parameters[i][j] = dict()\n",
    "                    self.parameters[i][j][\"mean\"] = np.mean(temparray)\n",
    "                    #print(self.parameters[i][j][\"mean\"]) \n",
    "                    #print(type(temparray))\n",
    "                    varian = np.var(temparray)\n",
    "                    if varian ==0:\n",
    "                        varian = 1e-6\n",
    "                    self.parameters[i][j][\"sigma\"] = varian\n",
    "                pass\n",
    "        for i in range(self.class_num):\n",
    "            self.pA[i][\"p\"] = self.pA[i][\"count\"]/self.train_data_num\n",
    "        \n",
    "    \n",
    "    def predict(self, Xtest):\n",
    "        probability = [0 for i in range(self.class_num)]\n",
    "        for i in range(self.class_num):\n",
    "            for j in range(len(self.feature_type)):\n",
    "                if self.feature_type[i] == 'b':\n",
    "                    if Xtest[j] in self.parameters[j]:\n",
    "                        probability[i] = probability[i] + np.log(self.parameters[j][Xtest[j]][i]*self.pA[i][\"p\"]/(self.pB[j][Xtest[j]][\"p\"]+1e-6)+1e-6)\n",
    "                    else:\n",
    "                        probability[i] = probability[i] + np.log(1e-6)\n",
    "                else:\n",
    "                    probability[i] = probability[i] + np.log(self.get_gaussian_value(Xtest[j],self.parameters[j][i][\"mean\"],self.parameters[j][i][\"sigma\"]))\n",
    "        bestclass = 0;\n",
    "        value = probability[0]\n",
    "        for i in range(self.class_num):\n",
    "            if probability[i] > value:\n",
    "                value = probability[i]\n",
    "                bestclass = i\n",
    "        return bestclass\n",
    "\n",
    "#for iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris['data'], iris['target']\n",
    "N, D = X.shape\n",
    "Ntrain = int(0.8*N)\n",
    "\n",
    "result_NBC = [0.0]*10\n",
    "result_LR = [0.0]*10\n",
    "for i in range(1000):\n",
    "    shuffler = np.random.permutation(N)\n",
    "    Xtrain = X[shuffler[:Ntrain]]\n",
    "    ytrain = y[shuffler[:Ntrain]]\n",
    "    Xtest = X[shuffler[Ntrain:]]\n",
    "    ytest = y[shuffler[Ntrain:]]\n",
    "    for k in range(10):\n",
    "        train_num = round((k+1)*Ntrain/10)\n",
    "        X_train_new = Xtrain[:train_num]\n",
    "        y_train_new = ytrain[:train_num]\n",
    "        nbc = NBC(['r','r','r','r'],4)\n",
    "        nbc.fit(X_train_new,y_train_new)\n",
    "        test_err = 0\n",
    "        for j in range(len(Xtest)):\n",
    "            if nbc.predict(Xtest[j,:]) != y[j]:\n",
    "                test_err = test_err + 1\n",
    "        result_NBC[k] = result_NBC[k] + test_err*1.0/len(Xtest)\n",
    "for i in range(10):\n",
    "    result_NBC[i] = result_NBC[i]/1000\n",
    "print(result_NBC)\n",
    "\n",
    "\n",
    "nbc = NBC(['r','r','r','r'],4)\n",
    "nbc.fit(X,y)\n",
    "correct = 0\n",
    "for i in range(len(y)):\n",
    "    print(\"  \")\n",
    "    print(nbc.predict(X[i,:]))\n",
    "    print(y[i])\n",
    "    if nbc.predict(X[i,:])==y[i]:\n",
    "        correct = correct + 1\n",
    "print(correct)\n",
    "print(len(y))\n",
    "print(correct/len(y))\n",
    "\n",
    "\n",
    "#voting dataset\n",
    "X, y = cp.load(open('voting.pickle','rb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
